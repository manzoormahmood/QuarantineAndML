{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline\n",
    "from pandas import DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url= 'https://www.imdb.com/search/title/?num_votes=100000,&sort=user_rating,desc&title_type=tv_series&'\n",
    "data=requests.get(url)\n",
    "news_data = []\n",
    "soup = BeautifulSoup(data.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "certi=[]#null\n",
    "rate=[]\n",
    "run=[]\n",
    "genre=[]\n",
    "gross=[]#null\n",
    "director=[]\n",
    "summary=[]\n",
    "\n",
    "\n",
    "movie_Data=soup.find_all('div',attrs = {'class':'lister-item-content'})\n",
    "\n",
    "for data in movie_Data:\n",
    "    name.append(data.h3.a.text)\n",
    "    run.append(data.find('span', attrs = {'class':'runtime'}).text)\n",
    "    rating=data.find('div', attrs = {'class':'inline-block ratings-imdb-rating'})\n",
    "    rate.append(rating['data-value'])\n",
    "    genre.append(data.find('span', attrs = {'class':'genre'}).text.replace('\\n', ' '))\n",
    "    temp=data.find('p',attrs = {'class':''})\n",
    "    director.append(temp.a.text)    \n",
    "    temp1=data.find_all('p',{'class':'text-muted'})\n",
    "    temp1=temp1[-1].text\n",
    "    summary.append(str(temp1.replace('\\n','').strip()))\n",
    "    \n",
    "df = pd.DataFrame({'Movie_Name':name,'rating':rate,'runtime':run,'genre':genre,'Director':director,'Summary':summary})\n",
    "df.head()\n",
    "\n",
    "df.to_csv('preview.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "Expanding Contraction,\n",
    "Remove Special char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a gangster family epic set in 1919 birmingham, england; centered on a gang who sew razor blades in the peaks of their caps, and their fierce boss tommy shelby.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from contractions import CONTRACTION_MAP\n",
    "\n",
    "contractions_re = re.compile('(%s)' % '|'.join(CONTRACTION_MAP.keys()))\n",
    "\n",
    "def expand_contractions(s, contractions_dict=CONTRACTION_MAP):\n",
    "    def replace(match):\n",
    "            return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)\n",
    "\n",
    "\n",
    "text=(\"A gangster family epic set in 1919 Birmingham, England; centered on a gang who sew razor blades in the peaks of their caps, and their fierce boss Tommy Shelby.\").lower()\n",
    "expand_contractions(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A gangster family epic set in 1919 Birmingham England centered on a gang who sew razor blades in the peaks of their caps and their fierce boss Tommy Shelby'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def remove_special_characters(text):\n",
    "    pattern = r'[^a-zA-z0-9\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "remove_special_characters(\"A gangster family epic set in 1919 Birmingham, England; centered on a gang who sew razor blades in the peaks of their caps, and their fierce boss Tommy Shelby.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming and Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.at eat play play play play stem stem stem rock corpora better.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "def simple_stemmer(text):\n",
    "    words = word_tokenize(text) \n",
    "    for w in words: \n",
    "        #print(w, \" : \", PorterStemmer().stem(w)) \n",
    "        text=re.sub(w,PorterStemmer().stem(w),text,count=1)\n",
    "    return text\n",
    "\n",
    "simple_stemmer(\"Eat Eating Playing played play playing Stemming stem stemmed rocks corpora better.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : good\n",
      "playing : play\n",
      "playing : playing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Fishing at swimming at the bank of river rock corpus better'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmatization (takes part of speech(pos) - default noun)\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "  \n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) \n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\")) \n",
    "  \n",
    "# a denotes adjective in \"pos\" \n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\")) \n",
    "print(\"playing :\", lemmatizer.lemmatize(\"playing\", pos =\"v\")) \n",
    "print(\"playing :\", lemmatizer.lemmatize(\"playing\", pos =\"a\")) \n",
    "def simple_lemmatization(text):\n",
    "    words = word_tokenize(text) \n",
    "    for w in words: \n",
    "        #print(w, \" : \", PorterStemmer().stem(w)) \n",
    "        text=re.sub(w,lemmatizer.lemmatize(w),text,count=2)\n",
    "    return text\n",
    "\n",
    "simple_lemmatization(\"Fishing at swimming at the banks of river rocks corpora better\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample sentence , showing stop words filtration .'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "tokenizer = ToktokTokenizer()\n",
    "\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "#stopword_list.remove('no')\n",
    "#stopword_list.remove('not')\n",
    "#stopword_list.remove('this')\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "remove_stopwords(\"This is a sample sentence, showing off the stop words filtration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding part of Speech (POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CC coordinating conjunction\n",
    "\n",
    "CD cardinal digit\n",
    "\n",
    "DT determiner\n",
    "\n",
    "EX existential there (like: “there is” … think of it like “there exists”)\n",
    "\n",
    "FW foreign word\n",
    "\n",
    "IN preposition/subordinating conjunction\n",
    "\n",
    "JJ adjective ‘big’\n",
    "\n",
    "JJR adjective, comparative ‘bigger’\n",
    "\n",
    "JJS adjective, superlative ‘biggest’\n",
    "\n",
    "LS list marker 1)\n",
    "\n",
    "MD modal could, will\n",
    "\n",
    "NN noun, singular ‘desk’\n",
    "\n",
    "NNS noun plural ‘desks’\n",
    "\n",
    "NNP proper noun, singular ‘Harrison’\n",
    "\n",
    "NNPS proper noun, plural ‘Americans’\n",
    "\n",
    "PDT predeterminer ‘all the kids’\n",
    "\n",
    "POS possessive ending parent‘s\n",
    "\n",
    "PRP personal pronoun I, he, she\n",
    "\n",
    "PRP$ possessive pronoun my, his, hers\n",
    "\n",
    "RB adverb very, silently,\n",
    "\n",
    "RBR adverb, comparative better\n",
    "\n",
    "RBS adverb, superlative best\n",
    "\n",
    "RP particle give up\n",
    "\n",
    "TO to go ‘to‘ the store.\n",
    "\n",
    "UH interjection errrrrrrrm\n",
    "\n",
    "VB verb, base form take\n",
    "\n",
    "VBD verb, past tense took\n",
    "\n",
    "VBG verb, gerund/present participle taking\n",
    "\n",
    "VBN verb, past participle taken\n",
    "\n",
    "VBP verb, sing. present, non-3d take\n",
    "\n",
    "VBZ verb, 3rd person sing. present takes\n",
    "\n",
    "WDT wh-determiner which\n",
    "\n",
    "WP wh-pronoun who, what\n",
    "\n",
    "WP$ possessive wh-pronoun whose\n",
    "\n",
    "WRB wh-abverb where, when"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heavens are above. (Adverb)\n",
    "\n",
    "The moral code of conduct is above the civil code of conduct. (Preposition)\n",
    "\n",
    "Read the sentence given above. (Adjective)\n",
    "\n",
    "Our blessings come from above. (Noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('heavens', 'NNS'), ('are', 'VBP'), ('above', 'IN'), ('The', 'DT'), ('moral', 'JJ'), ('code', 'NN'), ('of', 'IN'), ('conduct', 'NN'), ('is', 'VBZ'), ('above', 'IN'), ('the', 'DT'), ('civil', 'JJ'), ('code', 'NN'), ('of', 'IN'), ('conduct', 'NN'), ('Read', 'VB'), ('the', 'DT'), ('sentence', 'NN'), ('given', 'VBN'), ('above', 'IN'), ('Our', 'PRP$'), ('blessings', 'NNS'), ('come', 'VBP'), ('from', 'IN'), ('above', 'IN')]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#blob\n",
    "from textblob import TextBlob \n",
    "  \n",
    "text = (\"The heavens are above. The moral code of conduct is above the civil code of conduct. Read the sentence given above. Our blessings come from above.\") \n",
    "  \n",
    "# create a textblob object \n",
    "blob_object = TextBlob(text) \n",
    "  \n",
    "# Part-of-speech tags can be accessed  \n",
    "# through the tags property of blob object.' \n",
    "  \n",
    "# print word with pos tag. \n",
    "print(blob_object.tags) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origional</th>\n",
       "      <th>blob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heavens</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>are</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>above</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>moral</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>code</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>conduct</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>above</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>civil</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>code</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>conduct</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Read</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sentence</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>given</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>above</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Our</td>\n",
       "      <td>PRP$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>blessings</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>come</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>from</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>above</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    origional  blob\n",
       "0         The    DT\n",
       "1     heavens   NNS\n",
       "2         are   VBP\n",
       "3       above    IN\n",
       "4         The    DT\n",
       "5       moral    JJ\n",
       "6        code    NN\n",
       "7          of    IN\n",
       "8     conduct    NN\n",
       "9          is   VBZ\n",
       "10      above    IN\n",
       "11        the    DT\n",
       "12      civil    JJ\n",
       "13       code    NN\n",
       "14         of    IN\n",
       "15    conduct    NN\n",
       "16       Read    VB\n",
       "17        the    DT\n",
       "18   sentence    NN\n",
       "19      given   VBN\n",
       "20      above    IN\n",
       "21        Our  PRP$\n",
       "22  blessings   NNS\n",
       "23       come   VBP\n",
       "24       from    IN\n",
       "25      above    IN"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blob=pd.DataFrame(blob_object.tags,columns=['origional','blob'])\n",
    "df_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('heavens', 'NNS'), ('are', 'VBP'), ('above', 'IN'), ('.', '.'), ('The', 'DT'), ('moral', 'JJ'), ('code', 'NN'), ('of', 'IN'), ('conduct', 'NN'), ('is', 'VBZ'), ('above', 'IN'), ('the', 'DT'), ('civil', 'JJ'), ('code', 'NN'), ('of', 'IN'), ('conduct', 'NN'), ('.', '.'), ('Read', 'VB'), ('the', 'DT'), ('sentence', 'NN'), ('given', 'VBN'), ('above', 'IN'), ('.', '.'), ('Our', 'PRP$'), ('blessings', 'NNS'), ('come', 'VBP'), ('from', 'IN'), ('above', 'IN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#pos tagger nltk\n",
    "tokens=nltk.word_tokenize(\"The heavens are above. The moral code of conduct is above the civil code of conduct. Read the sentence given above. Our blessings come from above.\")\n",
    "print(nltk.pos_tag(tokens))\n",
    "\n",
    "df_spacy_nltk=pd.DataFrame(nltk.pos_tag(tokens),columns=['Origional',\"nltk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origional</th>\n",
       "      <th>nltk</th>\n",
       "      <th>spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heavens</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>are</td>\n",
       "      <td>VBP</td>\n",
       "      <td>AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>above</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>moral</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>code</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>conduct</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>above</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>civil</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>code</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>conduct</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Read</td>\n",
       "      <td>VB</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sentence</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>given</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>above</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Our</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>blessings</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>come</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>from</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>above</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Origional  nltk  spacy\n",
       "0         The    DT    DET\n",
       "1     heavens   NNS   NOUN\n",
       "2         are   VBP    AUX\n",
       "3       above    IN    ADJ\n",
       "4           .     .  PUNCT\n",
       "5         The    DT    DET\n",
       "6       moral    JJ    ADJ\n",
       "7        code    NN   NOUN\n",
       "8          of    IN    ADP\n",
       "9     conduct    NN   NOUN\n",
       "10         is   VBZ    AUX\n",
       "11      above    IN    ADP\n",
       "12        the    DT    DET\n",
       "13      civil    JJ    ADJ\n",
       "14       code    NN   NOUN\n",
       "15         of    IN    ADP\n",
       "16    conduct    NN   NOUN\n",
       "17          .     .  PUNCT\n",
       "18       Read    VB   VERB\n",
       "19        the    DT    DET\n",
       "20   sentence    NN   NOUN\n",
       "21      given   VBN   VERB\n",
       "22      above    IN    ADV\n",
       "23          .     .  PUNCT\n",
       "24        Our  PRP$    DET\n",
       "25  blessings   NNS   NOUN\n",
       "26       come   VBP   VERB\n",
       "27       from    IN    ADP\n",
       "28      above    IN    ADV\n",
       "29          .     .  PUNCT"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spacy\n",
    "import spacy \n",
    "spacy_df=[]\n",
    "# Load English tokenizer, tagger,  \n",
    "# parser, NER and word vectors \n",
    "nlp = spacy.load('en_core_web_sm') \n",
    "  \n",
    "# Process whole documents \n",
    "text = (\"The heavens are above. The moral code of conduct is above the civil code of conduct. Read the sentence given above. Our blessings come from above.\") \n",
    "doc = nlp(text) \n",
    "  \n",
    "# Token and Tag \n",
    "for token in doc:\n",
    "    #print(token, token.pos_)\n",
    "    spacy_df.append(token.pos_)\n",
    "    \n",
    "#print(\"Verbs:\", [token.text for token in doc if token.pos_ == \"VERB\"]) \n",
    "\n",
    "df_spacy_nltk['spacy']=spacy_df\n",
    "df_spacy_nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Entity Recognition\n",
    "\n",
    "spaCy supports the following entity types:\n",
    "\n",
    "PERSON\n",
    "\n",
    "NORP (nationalities, religious and political groups)\n",
    "\n",
    "FAC (buildings, airports etc.)\n",
    "\n",
    "ORG (organizations)\n",
    "\n",
    "GPE (countries, cities etc.)\n",
    "\n",
    "LOC (mountain ranges, water bodies etc.)\n",
    "\n",
    "PRODUCT (products)\n",
    "\n",
    "EVENT (event names)\n",
    "\n",
    "WORK_OF_ART (books, song titles)\n",
    "\n",
    "LAW (legal document titles)\n",
    "\n",
    "LANGUAGE (named languages)\n",
    "\n",
    "DATE, TIME, PERCENT, MONEY, QUANTITY, ORDINAL and CARDINAL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1919 DATE\n",
      "Birmingham GPE\n",
      "England GPE\n",
      "Tommy Shelby PERSON\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load('en_core_web_sm') \n",
    "\n",
    "sentence = \"A gangster family epic set in 1919 Birmingham, England; centered on a gang who sew razor blades in the peaks of their caps, and their fierce boss Tommy Shelby.\"\n",
    "\n",
    "doc = nlp(sentence) \n",
    "\n",
    "for ent in doc.ents: \n",
    "    #print(ent.text, ent.start_char, ent.end_char, ent.label_) \n",
    "    print(ent.text, ent.label_) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-30c224f564a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"en_core_web_sm\"\u001b[0m\u001b[1;33m)\u001b[0m           \u001b[1;31m# load model package \"en_core_web_sm\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#nlp = spacy.load(\"/path/to/en_core_web_sm\")  # load package from a directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"en\"\u001b[0m\u001b[1;33m)\u001b[0m                       \u001b[1;31m# load model with shortcut link \"en\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"This is a sentence.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\manzoor\\anaconda3\\envs\\venv\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\manzoor\\anaconda3\\envs\\venv\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Path or Path-like to model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")           # load model package \"en_core_web_sm\"\n",
    "#nlp = spacy.load(\"/path/to/en_core_web_sm\")  # load package from a directory\n",
    "nlp = spacy.load(\"en\")                       # load model with shortcut link \"en\"\n",
    "\n",
    "doc = nlp(\"This is a sentence.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
