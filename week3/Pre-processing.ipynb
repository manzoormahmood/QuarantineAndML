{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "url= 'https://www.imdb.com/search/title/?num_votes=100000,&sort=user_rating,desc&title_type=tv_series&'\n",
    "data=requests.get(url)\n",
    "news_data = []\n",
    "soup = BeautifulSoup(data.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "certi=[]#null\n",
    "rate=[]\n",
    "run=[]\n",
    "genre=[]\n",
    "gross=[]#null\n",
    "director=[]\n",
    "summary=[]\n",
    "\n",
    "\n",
    "movie_Data=soup.find_all('div',attrs = {'class':'lister-item-content'})\n",
    "\n",
    "for data in movie_Data:\n",
    "    name.append(data.h3.a.text)\n",
    "    run.append(data.find('span', attrs = {'class':'runtime'}).text)\n",
    "    rating=data.find('div', attrs = {'class':'inline-block ratings-imdb-rating'})\n",
    "    rate.append(rating['data-value'])\n",
    "    genre.append(data.find('span', attrs = {'class':'genre'}).text.replace('\\n', ' '))\n",
    "    temp=data.find('p',attrs = {'class':''})\n",
    "    director.append(temp.a.text)    \n",
    "    temp1=data.find_all('p',{'class':'text-muted'})\n",
    "    temp1=temp1[-1].text\n",
    "    summary.append(str(temp1.replace('\\n','').strip()))\n",
    "    \n",
    "df = pd.DataFrame({'Movie_Name':name,'rating':rate,'runtime':run,'genre':genre,'Director':director,'Summary':summary})\n",
    "df.head()\n",
    "\n",
    "df.to_csv('preview.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "Expanding Contraction,\n",
    "Remove Special char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a gangster family epic set in 1919 birmingham, england; centered on a gang who sew razor blades in the peaks of their caps, and their fierce boss tommy shelby.'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from contractions import CONTRACTION_MAP\n",
    "\n",
    "contractions_re = re.compile('(%s)' % '|'.join(CONTRACTION_MAP.keys()))\n",
    "\n",
    "def expand_contractions(s, contractions_dict=CONTRACTION_MAP):\n",
    "    def replace(match):\n",
    "            return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)\n",
    "\n",
    "\n",
    "text=(\"A gangster family epic set in 1919 Birmingham, England; centered on a gang who sew razor blades in the peaks of their caps, and their fierce boss Tommy Shelby.\").lower()\n",
    "expand_contractions(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A gangster family epic set in 1919 Birmingham England centered on a gang who sew razor blades in the peaks of their caps and their fierce boss Tommy Shelby'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def remove_special_characters(text):\n",
    "    pattern = r'[^a-zA-z0-9\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "remove_special_characters(\"A gangster family epic set in 1919 Birmingham, England; centered on a gang who sew razor blades in the peaks of their caps, and their fierce boss Tommy Shelby.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming and Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.at eat play play play play stem stem stem rock corpora better.'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "def simple_stemmer(text):\n",
    "    words = word_tokenize(text) \n",
    "    for w in words: \n",
    "        #print(w, \" : \", PorterStemmer().stem(w)) \n",
    "        text=re.sub(w,PorterStemmer().stem(w),text,count=1)\n",
    "    return text\n",
    "\n",
    "simple_stemmer(\"Eat Eating Playing played play playing Stemming stem stemmed rocks corpora better.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : good\n",
      "playing : play\n",
      "playing : playing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Fishing at swimming at the bank of river rock corpus better'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmatization (takes part of speech(pos) - default noun)\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "  \n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) \n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\")) \n",
    "  \n",
    "# a denotes adjective in \"pos\" \n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\")) \n",
    "print(\"playing :\", lemmatizer.lemmatize(\"playing\", pos =\"v\")) \n",
    "print(\"playing :\", lemmatizer.lemmatize(\"playing\", pos =\"a\")) \n",
    "def simple_lemmatization(text):\n",
    "    words = word_tokenize(text) \n",
    "    for w in words: \n",
    "        #print(w, \" : \", PorterStemmer().stem(w)) \n",
    "        text=re.sub(w,lemmatizer.lemmatize(w),text,count=2)\n",
    "    return text\n",
    "\n",
    "simple_lemmatization(\"Fishing at swimming at the banks of river rocks corpora better\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample sentence , showing stop words filtration .'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "tokenizer = ToktokTokenizer()\n",
    "\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "#stopword_list.remove('no')\n",
    "#stopword_list.remove('not')\n",
    "#stopword_list.remove('this')\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "remove_stopwords(\"This is a sample sentence, showing off the stop words filtration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
